{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Merging & Preparation for Wildfire Risk Prediction\n",
    "\n",
    "**Objective**: Merge all processed datasets into a unified dataset for ML model training\n",
    "\n",
    "**Datasets to Merge**:\n",
    "1. **Fire Data**: `fire_data_complete_unit_month.csv` - Fire occurrences by unit-month\n",
    "2. **Weather Data**: `unified_county_weather_2000_2025.csv` - County-level weather (43 counties)\n",
    "3. **Drought Data**: `drought_data_monthly_2000_2025.csv` - Statewide monthly drought\n",
    "4. **Population Data**: `population_data_long_format_2000_2025.csv` - County population (58 counties)\n",
    "5. **Topography Data**: `terrain_data_timeseries_2000_2025.csv` - County terrain features\n",
    "\n",
    "**Merging Strategy**:\n",
    "- **Primary Key**: County + Year + Month\n",
    "- **Fire Data**: Use Unit_ID mapping to counties\n",
    "- **Weather Data**: 43 counties with complete weather data\n",
    "- **Drought Data**: Statewide data applied to all counties\n",
    "- **Population Data**: 58 counties with yearly data (no Month column)\n",
    "- **Topography Data**: 58 counties with terrain features\n",
    "\n",
    "**Expected Output**: Unified dataset ready for ML model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ccfi-capp/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print('âœ… Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load All Processed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING ALL PROCESSED DATASETS\n",
      "================================================================================\n",
      "\n",
      "ðŸ”¥ Loading Fire Data...\n",
      "   Records: 34,008\n",
      "   Columns: ['Unit_ID', 'Year', 'Month', 'Fire_Count', 'Total_Acres', 'Avg_Acres', 'Max_Acres', 'Fire_Occurred', 'County']\n",
      "   Date range: 2000-2025\n",
      "\n",
      "ðŸŒ¤ï¸ Loading Weather Data...\n",
      "   Records: 423,808\n",
      "   Columns: ['County', 'Year', 'Month', 'Avg_Temp', 'Max_Temp', 'Min_Temp', 'Precipitation']\n",
      "   Counties: 43\n",
      "\n",
      "ðŸŒµ Loading Drought Data...\n",
      "   Records: 310\n",
      "   Columns: ['Year', 'Month', 'None', 'D0', 'D1', 'D2', 'D3', 'D4', 'Drought_Intensity_Score', 'Severe_Drought_Area', 'Has_D0', 'Has_D1', 'Has_D2', 'Has_D3', 'Has_D4']\n",
      "   Date range: 2000-2025\n",
      "\n",
      "ðŸ‘¥ Loading Population Data...\n",
      "   Records: 1,508\n",
      "   Columns: ['COUNTY', 'Year', 'Population']\n",
      "   Counties: 58\n",
      "\n",
      "â›°ï¸ Loading Topography Data...\n",
      "   Records: 18,096\n",
      "   Columns: ['Year', 'Month', 'County', 'Mean_Elevation', 'Max_Elevation', 'Min_Elevation', 'Mean_Slope', 'Max_Slope', 'Mean_Aspect', 'Terrain_Roughness']\n",
      "   Counties: 58\n",
      "\n",
      "âœ… All datasets loaded successfully!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load all processed datasets\n",
    "print('=' * 80)\n",
    "print('LOADING ALL PROCESSED DATASETS')\n",
    "print('=' * 80)\n",
    "\n",
    "data_dir = Path('../data/processed')\n",
    "\n",
    "# 1. Fire Data\n",
    "print('\\nðŸ”¥ Loading Fire Data...')\n",
    "fire_file = data_dir / 'fire_data_complete_unit_month.csv'\n",
    "fire_df = pd.read_csv(fire_file)\n",
    "print(f'   Records: {len(fire_df):,}')\n",
    "print(f'   Columns: {list(fire_df.columns)}')\n",
    "print(f'   Date range: {fire_df[\"Year\"].min()}-{fire_df[\"Year\"].max()}')\n",
    "\n",
    "# 2. Weather Data\n",
    "print('\\nðŸŒ¤ï¸ Loading Weather Data...')\n",
    "weather_file = data_dir / 'unified_county_weather_2000_2025.csv'\n",
    "weather_df = pd.read_csv(weather_file)\n",
    "print(f'   Records: {len(weather_df):,}')\n",
    "print(f'   Columns: {list(weather_df.columns)}')\n",
    "print(f'   Counties: {weather_df[\"County\"].nunique()}')\n",
    "\n",
    "# 3. Drought Data\n",
    "print('\\nðŸŒµ Loading Drought Data...')\n",
    "drought_file = data_dir / 'drought_data_monthly_2000_2025.csv'\n",
    "drought_df = pd.read_csv(drought_file)\n",
    "print(f'   Records: {len(drought_df):,}')\n",
    "print(f'   Columns: {list(drought_df.columns)}')\n",
    "print(f'   Date range: {drought_df[\"Year\"].min()}-{drought_df[\"Year\"].max()}')\n",
    "\n",
    "# 4. Population Data\n",
    "print('\\nðŸ‘¥ Loading Population Data...')\n",
    "pop_file = data_dir / 'population_data_long_format_2000_2025.csv'\n",
    "pop_df = pd.read_csv(pop_file)\n",
    "print(f'   Records: {len(pop_df):,}')\n",
    "print(f'   Columns: {list(pop_df.columns)}')\n",
    "print(f'   Counties: {pop_df[\"COUNTY\"].nunique()}')\n",
    "\n",
    "# 5. Topography Data\n",
    "print('\\nâ›°ï¸ Loading Topography Data...')\n",
    "terrain_file = data_dir / 'terrain_data_timeseries_2000_2025.csv'\n",
    "terrain_df = pd.read_csv(terrain_file)\n",
    "print(f'   Records: {len(terrain_df):,}')\n",
    "print(f'   Columns: {list(terrain_df.columns)}')\n",
    "print(f'   Counties: {terrain_df[\"County\"].nunique()}')\n",
    "\n",
    "print('\\nâœ… All datasets loaded successfully!')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Merging Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREPARING DATASETS FOR MERGING\n",
      "================================================================================\n",
      "   Fire data: (34008, 9) - Ready for merge\n",
      "   Weather data: (423808, 7) - Ready for merge\n",
      "   Population data: (1508, 3) - Ready for merge (Yearly data)\n",
      "   Terrain data: (18096, 10) - Ready for merge\n",
      "   Drought data: (310, 15) - Statewide (will merge separately)\n",
      "\n",
      "âœ… All datasets prepared for merging!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Prepare datasets for merging\n",
    "print('=' * 80)\n",
    "print('PREPARING DATASETS FOR MERGING')\n",
    "print('=' * 80)\n",
    "\n",
    "# Fire data: Already has County, Year, Month\n",
    "fire_merge = fire_df.copy()\n",
    "print(f'   Fire data: {fire_merge.shape} - Ready for merge')\n",
    "\n",
    "# Weather data: Already has County, Year, Month\n",
    "weather_merge = weather_df.copy()\n",
    "print(f'   Weather data: {weather_merge.shape} - Ready for merge')\n",
    "\n",
    "# Population data: Rename COUNTY to County (NO Month column)\n",
    "pop_merge = pop_df.copy()\n",
    "pop_merge = pop_merge.rename(columns={'COUNTY': 'County'})\n",
    "print(f'   Population data: {pop_merge.shape} - Ready for merge (Yearly data)')\n",
    "\n",
    "# Terrain data: Already has County, Year, Month\n",
    "terrain_merge = terrain_df.copy()\n",
    "print(f'   Terrain data: {terrain_merge.shape} - Ready for merge')\n",
    "\n",
    "# Drought data: Statewide data\n",
    "drought_merge = drought_df.copy()\n",
    "print(f'   Drought data: {drought_merge.shape} - Statewide (will merge separately)')\n",
    "\n",
    "print('\\nâœ… All datasets prepared for merging!')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perform Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MERGING ALL DATASETS\n",
      "================================================================================\n",
      "\n",
      "ðŸ”¥ Starting with Fire Data as base...\n",
      "   Base dataset: (34008, 9)\n",
      "\n",
      "ðŸŒ¤ï¸ Merging Weather Data...\n",
      "   After weather merge: (1017452, 13)\n",
      "\n",
      "ðŸ‘¥ Merging Population Data...\n",
      "   After population merge: (1017452, 14)\n",
      "\n",
      "â›°ï¸ Merging Terrain Data...\n",
      "   After terrain merge: (1017452, 21)\n",
      "\n",
      "ðŸŒµ Adding Drought Data (statewide)...\n",
      "   After drought merge: (1017452, 34)\n",
      "\n",
      "âœ… All datasets merged successfully!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Start merging process\n",
    "print('=' * 80)\n",
    "print('MERGING ALL DATASETS')\n",
    "print('=' * 80)\n",
    "\n",
    "# Start with Fire Data as base\n",
    "print('\\nðŸ”¥ Starting with Fire Data as base...')\n",
    "merged = fire_merge.copy()\n",
    "print(f'   Base dataset: {merged.shape}')\n",
    "\n",
    "# Merge with Weather data\n",
    "print('\\nðŸŒ¤ï¸ Merging Weather Data...')\n",
    "merged = merged.merge(\n",
    "    weather_merge,\n",
    "    on=['County', 'Year', 'Month'],\n",
    "    how='left'\n",
    ")\n",
    "print(f'   After weather merge: {merged.shape}')\n",
    "\n",
    "# Merge with Population data (NO Month column)\n",
    "print('\\nðŸ‘¥ Merging Population Data...')\n",
    "merged = merged.merge(\n",
    "    pop_merge,\n",
    "    on=['County', 'Year'],\n",
    "    how='left'\n",
    ")\n",
    "print(f'   After population merge: {merged.shape}')\n",
    "\n",
    "# Merge with Terrain data\n",
    "print('\\nâ›°ï¸ Merging Terrain Data...')\n",
    "merged = merged.merge(\n",
    "    terrain_merge,\n",
    "    on=['County', 'Year', 'Month'],\n",
    "    how='left'\n",
    ")\n",
    "print(f'   After terrain merge: {merged.shape}')\n",
    "\n",
    "# Add Drought data (statewide)\n",
    "print('\\nðŸŒµ Adding Drought Data (statewide)...')\n",
    "drought_merge_wide = drought_merge.set_index(['Year', 'Month'])\n",
    "for col in drought_merge.columns:\n",
    "    if col not in ['Year', 'Month']:\n",
    "        merged[col] = merged.apply(\n",
    "            lambda row: drought_merge_wide.loc[(row['Year'], row['Month']), col]\n",
    "            if (row['Year'], row['Month']) in drought_merge_wide.index\n",
    "            else np.nan, axis=1\n",
    "        )\n",
    "print(f'   After drought merge: {merged.shape}')\n",
    "\n",
    "print('\\nâœ… All datasets merged successfully!')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final Data Preparation & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAVING MERGED DATASET\n",
      "================================================================================\n",
      "ðŸ’¾ Saved merged dataset to: ../data/processed/merged_wildfire_dataset_2000_2025.csv\n",
      "   File size: 129.19 MB\n",
      "   Records: 1,017,452\n",
      "   Columns: 34\n",
      "\n",
      "ðŸ“Š FINAL DATASET SUMMARY:\n",
      "   Total records: 1,017,452\n",
      "   Unique counties: 43\n",
      "   Date range: 2000-2025\n",
      "   Fire occurrence rate: 10.77%\n",
      "\n",
      "ðŸŽ¯ Merged dataset ready for ML model training!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save the merged dataset\n",
    "print('=' * 80)\n",
    "print('SAVING MERGED DATASET')\n",
    "print('=' * 80)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = data_dir / 'merged_wildfire_dataset_2000_2025.csv'\n",
    "merged.to_csv(output_file, index=False)\n",
    "\n",
    "print(f'ðŸ’¾ Saved merged dataset to: {output_file}')\n",
    "print(f'   File size: {output_file.stat().st_size / (1024*1024):.2f} MB')\n",
    "print(f'   Records: {len(merged):,}')\n",
    "print(f'   Columns: {merged.shape[1]}')\n",
    "\n",
    "# Final summary\n",
    "print(f'\\nðŸ“Š FINAL DATASET SUMMARY:')\n",
    "print(f'   Total records: {len(merged):,}')\n",
    "print(f'   Unique counties: {merged[\"County\"].nunique()}')\n",
    "print(f'   Date range: {merged[\"Year\"].min()}-{merged[\"Year\"].max()}')\n",
    "print(f'   Fire occurrence rate: {(merged[\"Fire_Occurred\"] == 1).mean()*100:.2f}%')\n",
    "\n",
    "print(f'\\nðŸŽ¯ Merged dataset ready for ML model training!')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initial Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INITIAL DATA EXPLORATION\n",
      "================================================================================\n",
      "\n",
      "ðŸ” Missing Values Analysis:\n",
      "                         Missing Count  Missing Percentage\n",
      "Mean_Slope                     1017452          100.000000\n",
      "Terrain_Roughness              1017452          100.000000\n",
      "Mean_Aspect                    1017452          100.000000\n",
      "Max_Slope                      1017452          100.000000\n",
      "Min_Elevation                  1017452          100.000000\n",
      "Max_Elevation                  1017452          100.000000\n",
      "Mean_Elevation                 1017452          100.000000\n",
      "Population                     1017452          100.000000\n",
      "Max_Temp                          2284            0.224482\n",
      "Precipitation                     2284            0.224482\n",
      "Min_Temp                          2284            0.224482\n",
      "Avg_Temp                          2284            0.224482\n",
      "County                            1872            0.183989\n",
      "D1                                 218            0.021426\n",
      "Drought_Intensity_Score            218            0.021426\n",
      "Severe_Drought_Area                218            0.021426\n",
      "Has_D0                             218            0.021426\n",
      "D4                                 218            0.021426\n",
      "Has_D1                             218            0.021426\n",
      "Has_D2                             218            0.021426\n",
      "Has_D3                             218            0.021426\n",
      "D3                                 218            0.021426\n",
      "D2                                 218            0.021426\n",
      "Has_D4                             218            0.021426\n",
      "D0                                 218            0.021426\n",
      "None                               218            0.021426\n",
      "\n",
      "ðŸ“‹ Data Types:\n",
      "Unit_ID                     object\n",
      "Year                         int64\n",
      "Month                        int64\n",
      "Fire_Count                 float64\n",
      "Total_Acres                float64\n",
      "Avg_Acres                  float64\n",
      "Max_Acres                  float64\n",
      "Fire_Occurred              float64\n",
      "County                      object\n",
      "Avg_Temp                   float64\n",
      "Max_Temp                   float64\n",
      "Min_Temp                   float64\n",
      "Precipitation              float64\n",
      "Population                 float64\n",
      "Mean_Elevation             float64\n",
      "Max_Elevation              float64\n",
      "Min_Elevation              float64\n",
      "Mean_Slope                 float64\n",
      "Max_Slope                  float64\n",
      "Mean_Aspect                float64\n",
      "Terrain_Roughness          float64\n",
      "None                       float64\n",
      "D0                         float64\n",
      "D1                         float64\n",
      "D2                         float64\n",
      "D3                         float64\n",
      "D4                         float64\n",
      "Drought_Intensity_Score    float64\n",
      "Severe_Drought_Area        float64\n",
      "Has_D0                     float64\n",
      "Has_D1                     float64\n",
      "Has_D2                     float64\n",
      "Has_D3                     float64\n",
      "Has_D4                     float64\n",
      "dtype: object\n",
      "\n",
      "ðŸ“Š Basic Statistics:\n",
      "               Year         Month    Fire_Count   Total_Acres     Avg_Acres  \\\n",
      "count  1.017452e+06  1.017452e+06  1.017452e+06  1.017452e+06  1.017452e+06   \n",
      "mean   2.012343e+03  6.449788e+00  2.323628e-01  5.762470e+02  3.044779e+02   \n",
      "std    7.414185e+00  3.441977e+00  1.129557e+00  1.083299e+04  7.952379e+03   \n",
      "min    2.000000e+03  1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    2.006000e+03  3.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "50%    2.012000e+03  6.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "75%    2.019000e+03  9.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "max    2.025000e+03  1.200000e+01  5.600000e+01  1.032700e+06  1.032700e+06   \n",
      "\n",
      "          Max_Acres  Fire_Occurred      Avg_Temp      Max_Temp      Min_Temp  \\\n",
      "count  1.017452e+06   1.017452e+06  1.015168e+06  1.015168e+06  1.015168e+06   \n",
      "mean   5.018209e+02   1.076945e-01  5.826183e+01  7.042455e+01  4.609038e+01   \n",
      "std    9.997745e+03   3.099944e-01  1.221867e+01  1.430828e+01  1.036931e+01   \n",
      "min    0.000000e+00   0.000000e+00  2.480000e+01  3.340000e+01  1.630000e+01   \n",
      "25%    0.000000e+00   0.000000e+00  4.860000e+01  5.870000e+01  3.840000e+01   \n",
      "50%    0.000000e+00   0.000000e+00  5.720000e+01  6.950000e+01  4.530000e+01   \n",
      "75%    0.000000e+00   0.000000e+00  6.830000e+01  8.260000e+01  5.400000e+01   \n",
      "max    1.032700e+06   1.000000e+00  9.800000e+01  1.122000e+02  8.380000e+01   \n",
      "\n",
      "       Precipitation  Population  Mean_Elevation  Max_Elevation  \\\n",
      "count   1.015168e+06         0.0             0.0            0.0   \n",
      "mean    2.446507e+00         NaN             NaN            NaN   \n",
      "std     3.704736e+00         NaN             NaN            NaN   \n",
      "min     0.000000e+00         NaN             NaN            NaN   \n",
      "25%     1.200000e-01         NaN             NaN            NaN   \n",
      "50%     8.200000e-01         NaN             NaN            NaN   \n",
      "75%     3.180000e+00         NaN             NaN            NaN   \n",
      "max     3.321000e+01         NaN             NaN            NaN   \n",
      "\n",
      "       Min_Elevation  Mean_Slope  Max_Slope  Mean_Aspect  Terrain_Roughness  \\\n",
      "count            0.0         0.0        0.0          0.0                0.0   \n",
      "mean             NaN         NaN        NaN          NaN                NaN   \n",
      "std              NaN         NaN        NaN          NaN                NaN   \n",
      "min              NaN         NaN        NaN          NaN                NaN   \n",
      "25%              NaN         NaN        NaN          NaN                NaN   \n",
      "50%              NaN         NaN        NaN          NaN                NaN   \n",
      "75%              NaN         NaN        NaN          NaN                NaN   \n",
      "max              NaN         NaN        NaN          NaN                NaN   \n",
      "\n",
      "               None            D0            D1            D2            D3  \\\n",
      "count  1.017234e+06  1.017234e+06  1.017234e+06  1.017234e+06  1.017234e+06   \n",
      "mean   4.272614e+01  1.906463e+01  1.742514e+01  1.735024e+01  1.011152e+01   \n",
      "std    3.809923e+01  1.701890e+01  1.710093e+01  1.864961e+01  1.569609e+01   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    3.310000e+00  4.900000e+00  4.070000e+00  1.000000e-02  0.000000e+00   \n",
      "50%    3.898000e+01  1.553000e+01  1.269000e+01  1.467000e+01  0.000000e+00   \n",
      "75%    8.371000e+01  2.779000e+01  2.790000e+01  2.521000e+01  1.987000e+01   \n",
      "max    1.000000e+02  8.747000e+01  7.231000e+01  9.396000e+01  6.794000e+01   \n",
      "\n",
      "                 D4  Drought_Intensity_Score  Severe_Drought_Area  \\\n",
      "count  1.017234e+06             1.017234e+06         1.017234e+06   \n",
      "mean   5.886206e+00             1.060050e+02         3.334797e+01   \n",
      "std    1.410776e+01             1.108133e+02         3.710855e+01   \n",
      "min    0.000000e+00             0.000000e+00         0.000000e+00   \n",
      "25%    0.000000e+00             7.280000e+00         1.000000e-02   \n",
      "50%    0.000000e+00             7.610000e+01         2.116000e+01   \n",
      "75%    0.000000e+00             1.788400e+02         5.806000e+01   \n",
      "max    5.841000e+01             4.119000e+02         1.379500e+02   \n",
      "\n",
      "             Has_D0        Has_D1        Has_D2        Has_D3        Has_D4  \n",
      "count  1.017234e+06  1.017234e+06  1.017234e+06  1.017234e+06  1.017234e+06  \n",
      "mean   9.383249e-01  8.701577e-01  7.532996e-01  4.838769e-01  2.109937e-01  \n",
      "std    2.405646e-01  3.361300e-01  4.310910e-01  4.997402e-01  4.080141e-01  \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "25%    1.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  \n",
      "50%    1.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  \n",
      "75%    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00  \n",
      "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
      "\n",
      "âœ… Initial exploration complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Basic data exploration\n",
    "print('=' * 80)\n",
    "print('INITIAL DATA EXPLORATION')\n",
    "print('=' * 80)\n",
    "\n",
    "# Check for missing values\n",
    "print('\\nðŸ” Missing Values Analysis:')\n",
    "missing_data = merged.isnull().sum()\n",
    "missing_percent = (missing_data / len(merged)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percent\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "# Data types\n",
    "print('\\nðŸ“‹ Data Types:')\n",
    "print(merged.dtypes)\n",
    "\n",
    "# Basic statistics\n",
    "print('\\nðŸ“Š Basic Statistics:')\n",
    "print(merged.describe())\n",
    "\n",
    "print('\\nâœ… Initial exploration complete!')\n",
    "print('=' * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
