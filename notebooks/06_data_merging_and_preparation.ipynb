{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Merging & Preparation for ML Model\n",
    "\n",
    "## ðŸŽ¯ Objective\n",
    "\n",
    "This notebook merges all 4 datasets (fire, weather, drought, population) into a **unified dataset** ready for exploratory data analysis and machine learning modeling.\n",
    "\n",
    "## ðŸ“Š What This Notebook Does\n",
    "\n",
    "1. **Loads processed fire data** from CSV (complete unit-month grid)\n",
    "2. **Loads weather data** from NOAA Climate at a Glance (2000-2025)\n",
    "3. **Loads drought data** from US Drought Monitor (2000-2025)\n",
    "4. **Loads population data** from CA Department of Finance (2000-2025)\n",
    "5. **Merges everything** into single dataframe for ML modeling\n",
    "\n",
    "## ðŸ”¥ Key Change: Using Processed Fire CSV\n",
    "\n",
    "We now use the processed fire CSV file instead of raw geodatabase data for faster and cleaner processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully!\n",
      "ðŸ”¥ Using processed fire CSV file (no more raw data!)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('âœ… All libraries imported successfully!')\n",
    "print('ðŸ”¥ Using processed fire CSV file (no more raw data!)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: LOADING FIRE DATA FROM PROCESSED CSV\n",
      "============================================================\n",
      "âœ… Loaded 34,008 fire records from processed CSV\n",
      "   Shape: (34008, 9)\n",
      "   Available columns: ['Unit_ID', 'Year', 'Month', 'Fire_Count', 'Total_Acres', 'Avg_Acres', 'Max_Acres', 'Fire_Occurred', 'County']\n",
      "\n",
      "Dataset header (first 5 rows):\n",
      "  Unit_ID  Year  Month  Fire_Count  Total_Acres  Avg_Acres  Max_Acres  \\\n",
      "0     ADR  2000      1         0.0          0.0        0.0        0.0   \n",
      "1     ADR  2000      2         0.0          0.0        0.0        0.0   \n",
      "2     ADR  2000      3         0.0          0.0        0.0        0.0   \n",
      "3     ADR  2000      4         0.0          0.0        0.0        0.0   \n",
      "4     ADR  2000      5         0.0          0.0        0.0        0.0   \n",
      "\n",
      "   Fire_Occurred  County  \n",
      "0            0.0  ALPINE  \n",
      "1            0.0  ALPINE  \n",
      "2            0.0  ALPINE  \n",
      "3            0.0  ALPINE  \n",
      "4            0.0  ALPINE  \n",
      "\n",
      "Dataset info:\n",
      "   Shape: (34008, 9)\n",
      "   Columns: ['Unit_ID', 'Year', 'Month', 'Fire_Count', 'Total_Acres', 'Avg_Acres', 'Max_Acres', 'Fire_Occurred', 'County']\n",
      "\n",
      "Sample fire data (key columns):\n",
      "  Unit_ID  County  Year  Month  Fire_Occurred  Fire_Count\n",
      "0     ADR  ALPINE  2000      1            0.0         0.0\n",
      "1     ADR  ALPINE  2000      2            0.0         0.0\n",
      "2     ADR  ALPINE  2000      3            0.0         0.0\n",
      "3     ADR  ALPINE  2000      4            0.0         0.0\n",
      "4     ADR  ALPINE  2000      5            0.0         0.0\n",
      "\n",
      "âœ… Fire data statistics:\n",
      "   Date range: 2000-2025\n",
      "   Unique units: 109\n",
      "   Unique counties: 43\n",
      "   Fire occurrence rate: 11.45%\n",
      "   County mapping: 32,136/34,008 records (94.5%)\n",
      "\n",
      "ðŸŽ¯ Fire data is ready for merging with other datasets!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Fire Data from Processed CSV\n",
    "print('='*60)\n",
    "print('STEP 1: LOADING FIRE DATA FROM PROCESSED CSV')\n",
    "print('='*60)\n",
    "\n",
    "# Load processed fire data from CSV (with complete unit-month grid)\n",
    "fire_csv_path = Path('../data/processed/fire_data_complete_unit_month.csv')\n",
    "fires_df = pd.read_csv(fire_csv_path)\n",
    "\n",
    "print(f'âœ… Loaded {len(fires_df):,} fire records from processed CSV')\n",
    "print(f'   Shape: {fires_df.shape}')\n",
    "print(f'   Available columns: {list(fires_df.columns)}')\n",
    "\n",
    "# Show dataset header and sample data\n",
    "print(f'\\nDataset header (first 5 rows):')\n",
    "print(fires_df.head(5))\n",
    "\n",
    "print(f'\\nDataset info:')\n",
    "print(f'   Shape: {fires_df.shape}')\n",
    "print(f'   Columns: {list(fires_df.columns)}')\n",
    "\n",
    "print(f'\\nSample fire data (key columns):')\n",
    "print(fires_df[['Unit_ID', 'County', 'Year', 'Month', 'Fire_Occurred', 'Fire_Count']].head(5))\n",
    "\n",
    "# Check data statistics\n",
    "print(f'\\nâœ… Fire data statistics:')\n",
    "print(f'   Date range: {fires_df[\"Year\"].min()}-{fires_df[\"Year\"].max()}')\n",
    "print(f'   Unique units: {fires_df[\"Unit_ID\"].nunique()}')\n",
    "print(f'   Unique counties: {fires_df[\"County\"].nunique()}')\n",
    "print(f'   Fire occurrence rate: {(fires_df[\"Fire_Occurred\"] == 1).mean()*100:.2f}%')\n",
    "\n",
    "# Check county mapping\n",
    "mapped_counties = fires_df['County'].notna().sum()\n",
    "total_records = len(fires_df)\n",
    "print(f'   County mapping: {mapped_counties:,}/{total_records:,} records ({mapped_counties/total_records*100:.1f}%)')\n",
    "\n",
    "print(f'\\nðŸŽ¯ Fire data is ready for merging with other datasets!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit_ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Fire_Count</th>\n",
       "      <th>Total_Acres</th>\n",
       "      <th>Avg_Acres</th>\n",
       "      <th>Max_Acres</th>\n",
       "      <th>Fire_Occurred</th>\n",
       "      <th>County</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADR</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ALPINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADR</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ALPINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADR</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ALPINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADR</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ALPINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADR</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ALPINE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unit_ID  Year  Month  Fire_Count  Total_Acres  Avg_Acres  Max_Acres  \\\n",
       "0     ADR  2000      1         0.0          0.0        0.0        0.0   \n",
       "1     ADR  2000      2         0.0          0.0        0.0        0.0   \n",
       "2     ADR  2000      3         0.0          0.0        0.0        0.0   \n",
       "3     ADR  2000      4         0.0          0.0        0.0        0.0   \n",
       "4     ADR  2000      5         0.0          0.0        0.0        0.0   \n",
       "\n",
       "   Fire_Occurred  County  \n",
       "0            0.0  ALPINE  \n",
       "1            0.0  ALPINE  \n",
       "2            0.0  ALPINE  \n",
       "3            0.0  ALPINE  \n",
       "4            0.0  ALPINE  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fires_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALAMEDA', 'ALPINE', 'AMADOR', 'BUTTE', 'COLUSA', 'CONTRA COSTA', 'DEL NORTE', 'EL DORADO', 'FRESNO', 'GLENN', 'HUMBOLDT', 'IMPERIAL', 'INYO', 'KERN', 'LAKE', 'LOS ANGELES', 'MADERA', 'MARIN', 'MARIPOSA', 'MENDOCINO', 'NEVADA', 'PLACER', 'PLUMAS', 'RIVERSIDE', 'SACRAMENTO', 'SAN BERNARDINO', 'SAN DIEGO', 'SAN JOAQUIN', 'SAN LUIS OBISPO', 'SAN MATEO', 'SANTA CLARA', 'SANTA CRUZ', 'SHASTA', 'SISKIYOU', 'SOLANO', 'SONOMA', 'STANISLAUS', 'TEHAMA', 'TRINITY', 'TULARE', 'TUOLUMNE', 'VENTURA', 'YOLO', 'nan']\n"
     ]
    }
   ],
   "source": [
    "# 1. Get unique values.\n",
    "unique_values = fires_df['County'].unique()\n",
    "\n",
    "# 2. Convert all elements to strings (str)\n",
    "#    This handles the mix of floats and strings.\n",
    "unique_strings = [str(x) for x in unique_values]\n",
    "\n",
    "# 3. Sort the list of strings\n",
    "sorted_counties = sorted(unique_strings)\n",
    "\n",
    "# Print the result\n",
    "print(sorted_counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fires_df.County.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2: LOADING WEATHER DATA\n",
      "============================================================\n",
      "Loading California climate data (2000-2025)...\n",
      "âœ… Loaded all 4 weather datasets\n",
      "Avg temp columns: ['200002', '47.2']\n",
      "Max temp columns: ['200002', '56']\n",
      "Min temp columns: ['200002', '38.4']\n",
      "Precip columns: ['200002', '6.93']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load Weather Data\n",
    "print('='*60)\n",
    "print('STEP 2: LOADING WEATHER DATA')\n",
    "print('='*60)\n",
    "\n",
    "# Load weather data from CSV files\n",
    "weather_dir = Path('../data/raw/weather')\n",
    "\n",
    "# Load all 4 weather CSV files\n",
    "avg_temp_file = weather_dir / 'California-Average-Monthly-Temperature-2000-2025.csv'\n",
    "max_temp_file = weather_dir / 'California-Max-Monthly-Temperature-2000-2025.csv'\n",
    "min_temp_file = weather_dir / 'California-Min-Monthly-Temperature-2000-2025.csv'\n",
    "precip_file = weather_dir / 'California-Monthly-Precipitation-2000-2025.csv'\n",
    "\n",
    "print('Loading California climate data (2000-2025)...')\n",
    "\n",
    "# Load each dataset\n",
    "avg_temp_df = pd.read_csv(avg_temp_file, skiprows=4)  # Skip comment lines\n",
    "max_temp_df = pd.read_csv(max_temp_file, skiprows=4)\n",
    "min_temp_df = pd.read_csv(min_temp_file, skiprows=4)\n",
    "precip_df = pd.read_csv(precip_file, skiprows=4)\n",
    "\n",
    "print(f\"âœ… Loaded all 4 weather datasets\")\n",
    "\n",
    "# Check column names first\n",
    "print(f'Avg temp columns: {list(avg_temp_df.columns)}')\n",
    "print(f'Max temp columns: {list(max_temp_df.columns)}')\n",
    "print(f'Min temp columns: {list(min_temp_df.columns)}')\n",
    "print(f'Precip columns: {list(precip_df.columns)}')\n",
    "\n",
    "# Combine into single dataframe\n",
    "climate_df = pd.concat([\n",
    "    avg_temp_df.rename(columns={'Value': 'Avg_Temp_F'}),\n",
    "    max_temp_df.rename(columns={'Value': 'Max_Temp_F'}),\n",
    "    min_temp_df.rename(columns={'Value': 'Min_Temp_F'}),\n",
    "    precip_df.rename(columns={'Value': 'Precip_Inches'})\n",
    "], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>200002</th>\n",
       "      <th>47.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200003</td>\n",
       "      <td>50.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200004</td>\n",
       "      <td>57.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200005</td>\n",
       "      <td>63.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200006</td>\n",
       "      <td>72.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200007</td>\n",
       "      <td>73.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   200002  47.2\n",
       "0  200003  50.2\n",
       "1  200004  57.8\n",
       "2  200005  63.9\n",
       "3  200006  72.2\n",
       "4  200007  73.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_temp_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Date', 'Avg_Temp_F', 'Max_Temp_F', 'Min_Temp_F', 'Precip_Inches'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_g/l0lpgm7n2_57n0f0_n9br4qh0000gn/T/ipykernel_8687/2335301018.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Select only the columns we want\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclimate_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclimate_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Avg_Temp_F'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Max_Temp_F'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Min_Temp_F'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Precip_Inches'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Parse dates and add Year/Month columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclimate_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclimate_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3510\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3511\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3513\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5794\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5796\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5798\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5854\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5855\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5856\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5858\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Date', 'Avg_Temp_F', 'Max_Temp_F', 'Min_Temp_F', 'Precip_Inches'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Select only the columns we want\n",
    "climate_df = climate_df[['Date', 'Avg_Temp_F', 'Max_Temp_F', 'Min_Temp_F', 'Precip_Inches']]\n",
    "\n",
    "# Parse dates and add Year/Month columns\n",
    "climate_df['Date'] = pd.to_datetime(climate_df['Date'])\n",
    "climate_df['Year'] = climate_df['Date'].dt.year\n",
    "climate_df['Month'] = climate_df['Date'].dt.month\n",
    "\n",
    "print(f'âœ… Weather data loaded: {len(climate_df)} records')\n",
    "print(f'   Date range: {climate_df[\"Date\"].min()} to {climate_df[\"Date\"].max()}')\n",
    "\n",
    "# Show dataset header\n",
    "print(f'\\nWeather dataset header (first 5 rows):')\n",
    "print(climate_df.head(5))\n",
    "\n",
    "print(f'\\nDataset info:')\n",
    "print(f'   Shape: {climate_df.shape}')\n",
    "print(f'   Columns: {list(climate_df.columns)}')\n",
    "\n",
    "print(f'\\nSample weather data:')\n",
    "print(climate_df[['Date', 'Year', 'Month', 'Avg_Temp_F', 'Max_Temp_F', 'Min_Temp_F', 'Precip_Inches']].head(5))\n",
    "\n",
    "print(f'\\nðŸŽ¯ Weather data is ready for merging!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
